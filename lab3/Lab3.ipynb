{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "from functional import seq,pseq\n",
    "from fn import _\n",
    "import requests as r\n",
    "from typing import Set, Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "#print(r.delete(\"http://localhost:9200/law_index6\").json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index_body = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_custom_analyzer\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"law_synonyms\",\n",
    "            \"morfologik_stem\",\n",
    "            \"lowercase\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"filter\": {\n",
    "        \"law_synonyms\": {\n",
    "          \"type\": \"synonym\",\n",
    "          \"synonyms\": [\n",
    "            \"kpc  => kodeks postępowania cywilnego\",\n",
    "            \"kpk => kodeks postępowania karnego\",\n",
    "            \"kk => kodeks karny\",\n",
    "            \"kc => kodeks cywilny\"\n",
    "            ]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"_doc\": {\n",
    "      \"properties\": {\n",
    "        \"title\": {\n",
    "          \"type\": \"text\",\n",
    "          \"analyzer\": \"default\",\n",
    "          \"search_analyzer\": \"default\",\n",
    "          \"search_quote_analyzer\": \"default\"\n",
    "        },\n",
    "        \"content\": {\n",
    "          \"type\": \"text\",\n",
    "          \"term_vector\": \"with_positions_offsets_payloads\",\n",
    "          \"analyzer\": \"my_custom_analyzer\",\n",
    "          \"search_analyzer\": \"my_custom_analyzer\",\n",
    "          \"search_quote_analyzer\": \"my_custom_analyzer\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# create_resp = r.put(\"http://localhost:9200/law_index6\",json=create_index_body)\n",
    "# print(create_resp.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import os\n",
    "es = Elasticsearch(retry_on_timeout=True)\n",
    "\n",
    "actions = [{\n",
    "    \"_index\": \"law_index6\",\n",
    "    \"_id\": i,\n",
    "    \"_type\": \"_doc\",\n",
    "    \"_source\": {\n",
    "        \"content\": open(\"../ustawy/\" + file).read(),\n",
    "        \"filename\": file\n",
    "    }\n",
    "} for i, file in enumerate(os.listdir(\"../ustawy\"))]\n",
    "\n",
    "# helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_termvectors(doc_id):\n",
    "    data = {                                                                                      \n",
    "      \"fields\" : [\"content\"],                                                                                                         \n",
    "      \"offsets\" : True,                                                                                         \n",
    "      \"positions\" : True,                                                                                                                                                                                                                                                          \n",
    "      \"term_statistics\" : True,                                       \n",
    "      \"field_statistics\" : True                                                                                                                                                                                                                                                    \n",
    "    }   \n",
    "    url = \"http://localhost:9200/law_index6/_doc/{}/_termvectors\".format(doc_id)\n",
    "    response = r.post(url,json=data)\n",
    "    return json.loads(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def frequency_extractor(term_dict):\n",
    "    return term_dict['term_freq']\n",
    "\n",
    "def body_to_freqs(body): #Sequence[str,int]\n",
    "    return seq(body['term_vectors']['content']['terms'].items())\\\n",
    "        .filter(lambda x: x[0].isalpha())\\\n",
    "        .map(lambda x: (x[0],frequency_extractor(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freqs(doc_id): #Sequence[Term,Ocurrences]\n",
    "    body = get_termvectors(doc_id)\n",
    "    return body_to_freqs(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get docs from index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids():\n",
    "    match_all_query = {\n",
    "      \"query\": {\n",
    "        \"match_all\": {}\n",
    "      },\n",
    "        \"size\":1200,\n",
    "      \"_source\": \"_id\"\n",
    "    }\n",
    "\n",
    "    resp = r.post(\"http://localhost:9200/law_index6/_search\",json=match_all_query)\n",
    "    hits = resp.json()['hits']['hits']\n",
    "    return seq(hits).map(lambda x: x['_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_list = get_ids()\\\n",
    ".flat_map(lambda ajdi: get_freqs(ajdi))\\\n",
    ".group_by(lambda x:x[0])\\\n",
    ".map(lambda group: (\n",
    "    group[0],\n",
    "    seq(group[1]).map(lambda x:x[1]).sum()\n",
    "))\\\n",
    ".filter(lambda x:x[0].isalpha() and len(x[0])>=2)\\\n",
    ".order_by(lambda x: -x[1])\n",
    "# frequency_list.to_csv(\"frequency_list.out\")\n",
    "frequency_list = seq.csv(\"frequency_list.out\").map(lambda x: (x[0],int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>wiek   </td><td style=\"text-align: right;\">188681</td></tr>\n",
       "<tr><td>ojciec </td><td style=\"text-align: right;\"> 65253</td></tr>\n",
       "<tr><td>ocean  </td><td style=\"text-align: right;\"> 65202</td></tr>\n",
       "<tr><td>do     </td><td style=\"text-align: right;\"> 61002</td></tr>\n",
       "<tr><td>artykuł</td><td style=\"text-align: right;\"> 53912</td></tr>\n",
       "<tr><td>usta   </td><td style=\"text-align: right;\"> 53705</td></tr>\n",
       "<tr><td>na     </td><td style=\"text-align: right;\"> 50809</td></tr>\n",
       "<tr><td>który  </td><td style=\"text-align: right;\"> 49562</td></tr>\n",
       "<tr><td>on     </td><td style=\"text-align: right;\"> 49331</td></tr>\n",
       "<tr><td>się    </td><td style=\"text-align: right;\"> 46522</td></tr>\n",
       "</tbody>\n",
       "</table><p>Showing 10 of 20556 rows"
      ],
      "text/plain": [
       "[('wiek', 188681), ('ojciec', 65253), ('ocean', 65202), ('do', 61002), ('artykuł', 53912), ('usta', 53705), ('na', 50809), ('który', 49562), ('on', 49331), ('się', 46522), ('numer', 46396), ('lub', 46100), ('lubić', 46100), ('pozycja', 45798), ('rok', 42917), ('oraz', 33660), ('być', 31195), ('arta', 30992), ('mowa', 28912), ('dzień', 28017), ('ten', 27317), ('ustawa', 25092), ('nie', 23070), ('przez', 21027), ('punkt', 19900), ('określić', 19127), ('brzmieć', 17977), ('brzmienie', 17975), ('przepis', 17756), ('móc', 16797), ('oda', 16774), ('sprawa', 16608), ('od', 16124), ('minister', 15836), ('osoba', 15192), ('to', 14370), ('właściwy', 14057), ('wat', 13812), ('po', 13601), ('określony', 13487), ('inny', 12289), ('wyraz', 12202), ('może', 12148), ('jeżeli', 12117), ('organ', 11626), ('otrzymywać', 11373), ('za', 11164), ('prawo', 10690), ('sprawić', 10040), ('praca', 10021), ('prowadzić', 9720), ('prawy', 9655), ('stosować', 9515), ('zakres', 9333), ('postępowanie', 8834), ('wniosek', 8813), ('alba', 8760), ('albo', 8760), ('podstawa', 8696), ('przypadek', 8680), ('postępować', 8574), ('dodawać', 8498), ('jednostka', 8497), ('termin', 8366), ('wykonywać', 8346), ('droga', 8278), ('środek', 8114), ('sąd', 7981), ('dla', 7946), ('były', 7922), ('państwo', 7731), ('polski', 7660), ('rada', 7434), ('działalność', 7422), ('bieżący', 7296), ('zmiana', 7210), ('informacja', 6994), ('bardzo', 6943), ('warunek', 6943), ('wydać', 6905), ('bar', 6895), ('jednostki', 6853), ('środki', 6837), ('urząd', 6833), ('okres', 6831), ('rad', 6803), ('publiczny', 6774), ('dać', 6707), ('mieć', 6655), ('dany', 6646), ('umowa', 6525), ('nizać', 6479), ('niż', 6479), ('niża', 6479), ('rozporządzenie', 6457), ('ochrona', 6449), ('tym', 6399), ('rozporządzić', 6334), ('bycie', 6156), ('warunki', 6123), ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_data = frequency_list.take(20)\n",
    "freq_series = pd.Series(plot_data.map(lambda x:x[1]).to_list())\n",
    "\n",
    "x_labels = plot_data.map(lambda x:x[0]).enumerate().map(lambda enum: enum[1] +\":  \"+ str(enum[0]+1)).to_list()\n",
    "\n",
    "# Plot the figure.\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = freq_series.plot(kind='bar')\n",
    "# ax.set_title('Rank')\n",
    "ax.set_xlabel('Rank')\n",
    "ax.set_ylabel('Occurrences')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "rects = ax.patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using polimorfologik \n",
    "> First i had to create wordlist from dictionary:\n",
    "``` bash\n",
    "cat polimorfologik-2.1.txt| gawk -F\";\" '{print tolower($1)\"\\n\"tolower($2)}' | grep -v \"-\" | uniq > ../polibash.out\n",
    "```\n",
    "> `gawk` is GNU awk (linuxy version of awk that supports utf-8 in tolower) on linux use `awk`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_dict = set(map(lambda x: x[:-1] ,open(\"polibash.out\").readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 words not in dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top30_non_in_dict = frequency_list.filter(lambda x: x[0] not in polish_dict).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functional.streams import Sequence\n",
    "\n",
    "def display_seq(sequence:Sequence,rows:int)-> None:\n",
    "        sequence._repr_html_= lambda :sequence.tabulate(rows,tablefmt='html')\n",
    "        display(sequence)\n",
    "        sequence._repr_html_= lambda :sequence.tabulate(10,tablefmt='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>margin    </td><td style=\"text-align: right;\">1111</td></tr>\n",
       "<tr><td>późn      </td><td style=\"text-align: right;\">1080</td></tr>\n",
       "<tr><td>family    </td><td style=\"text-align: right;\"> 543</td></tr>\n",
       "<tr><td>text      </td><td style=\"text-align: right;\"> 531</td></tr>\n",
       "<tr><td>mso       </td><td style=\"text-align: right;\"> 448</td></tr>\n",
       "<tr><td>bottom    </td><td style=\"text-align: right;\"> 399</td></tr>\n",
       "<tr><td>face      </td><td style=\"text-align: right;\"> 327</td></tr>\n",
       "<tr><td>panose    </td><td style=\"text-align: right;\"> 326</td></tr>\n",
       "<tr><td>serif     </td><td style=\"text-align: right;\"> 325</td></tr>\n",
       "<tr><td>gmo       </td><td style=\"text-align: right;\"> 298</td></tr>\n",
       "<tr><td>times     </td><td style=\"text-align: right;\"> 296</td></tr>\n",
       "<tr><td>iv        </td><td style=\"text-align: right;\"> 272</td></tr>\n",
       "<tr><td>sa        </td><td style=\"text-align: right;\"> 266</td></tr>\n",
       "<tr><td>name      </td><td style=\"text-align: right;\"> 254</td></tr>\n",
       "<tr><td>size      </td><td style=\"text-align: right;\"> 248</td></tr>\n",
       "<tr><td>left      </td><td style=\"text-align: right;\"> 233</td></tr>\n",
       "<tr><td>right     </td><td style=\"text-align: right;\"> 233</td></tr>\n",
       "<tr><td>sww       </td><td style=\"text-align: right;\"> 227</td></tr>\n",
       "<tr><td>skw       </td><td style=\"text-align: right;\"> 196</td></tr>\n",
       "<tr><td>ex        </td><td style=\"text-align: right;\"> 169</td></tr>\n",
       "<tr><td>height    </td><td style=\"text-align: right;\"> 168</td></tr>\n",
       "<tr><td>line      </td><td style=\"text-align: right;\"> 168</td></tr>\n",
       "<tr><td>ike       </td><td style=\"text-align: right;\"> 162</td></tr>\n",
       "<tr><td>vi        </td><td style=\"text-align: right;\"> 154</td></tr>\n",
       "<tr><td>indent    </td><td style=\"text-align: right;\"> 121</td></tr>\n",
       "<tr><td>remediacji</td><td style=\"text-align: right;\"> 120</td></tr>\n",
       "<tr><td>vii       </td><td style=\"text-align: right;\"> 111</td></tr>\n",
       "<tr><td>ure       </td><td style=\"text-align: right;\"> 103</td></tr>\n",
       "<tr><td>uke       </td><td style=\"text-align: right;\">  97</td></tr>\n",
       "<tr><td>kn        </td><td style=\"text-align: right;\">  95</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[('margin', 1111), ('późn', 1080), ('family', 543), ('text', 531), ('mso', 448), ('bottom', 399), ('face', 327), ('panose', 326), ('serif', 325), ('gmo', 298), ('times', 296), ('iv', 272), ('sa', 266), ('name', 254), ('size', 248), ('left', 233), ('right', 233), ('sww', 227), ('skw', 196), ('ex', 169), ('height', 168), ('line', 168), ('ike', 162), ('vi', 154), ('indent', 121), ('remediacji', 120), ('vii', 111), ('ure', 103), ('uke', 97), ('kn', 95)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_seq(top30_non_in_dict,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> English words appeared here from `2003_1187.txt`. This file contains some CSS- like thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words with lte 3 occurrences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_lt3_occurrences= frequency_list.filter(lambda x: x[1] <=3 and x[0] not in polish_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>autologicznego        </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>eutc                  </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>isbt                  </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>przeszczepień         </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>mikroprzedsiębiorcy   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>xxxvi                 </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>apostille             </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>adaptacyjnoopiekuńcze </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>hz                    </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>naukowobadawcze       </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>operacyjnoratowniczego</td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>trifenyle             </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>podwielokrotności     </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>warszawacentrum       </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>orzecznikw            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>przeprowa             </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>szczegłowe            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>ności                 </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>aw                    </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>cał                   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>cego                  </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>chemiczn              </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>cych                  </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>cyjanamidowy          </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>cza                   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>deklarow              </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>dimocznika            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>dnego                 </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>enia                  </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>enodimoczn            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>ia                    </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>iu                    </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>jednowapniowy         </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>kow                   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>krotonylide           </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>ktu                   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>kwadratowyc           </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>lidenod               </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>mikroeleme            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>naturalneg            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>nodimocznik           </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>oru                   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>osiarc                </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>otrzymywa             </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>posodowe              </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>posodowego            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>postac                </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>produ                 </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>przeliczen            </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>rozpu                 </td><td style=\"text-align: right;\">3</td></tr>\n",
       "</tbody>\n",
       "</table><p>Showing 50 of 2832 rows"
      ],
      "text/plain": [
       "[('autologicznego', 3), ('eutc', 3), ('isbt', 3), ('przeszczepień', 3), ('mikroprzedsiębiorcy', 3), ('xxxvi', 3), ('apostille', 3), ('adaptacyjnoopiekuńcze', 3), ('hz', 3), ('naukowobadawcze', 3), ('operacyjnoratowniczego', 3), ('trifenyle', 3), ('podwielokrotności', 3), ('warszawacentrum', 3), ('orzecznikw', 3), ('przeprowa', 3), ('szczegłowe', 3), ('ności', 3), ('aw', 3), ('cał', 3), ('cego', 3), ('chemiczn', 3), ('cych', 3), ('cyjanamidowy', 3), ('cza', 3), ('deklarow', 3), ('dimocznika', 3), ('dnego', 3), ('enia', 3), ('enodimoczn', 3), ('ia', 3), ('iu', 3), ('jednowapniowy', 3), ('kow', 3), ('krotonylide', 3), ('ktu', 3), ('kwadratowyc', 3), ('lidenod', 3), ('mikroeleme', 3), ('naturalneg', 3), ('nodimocznik', 3), ('oru', 3), ('osiarc', 3), ('otrzymywa', 3), ('posodowe', 3), ('posodowego', 3), ('postac', 3), ('produ', 3), ('przeliczen', 3), ('rozpu', 3), ('roztwo', 3), ('roślinn', 3), ('tość', 3), ('ureafor', 3), ('znych', 3), ('zu', 3), ('zwierzęceg', 3), ('gmdss', 3), ('instrumentalistyki', 3), ('zbywczej', 3), ('zbywczą', 3), ('oszczędnościowokredytowych', 3), ('auditorów', 3), ('hydrologicznometeorologicznych', 3), ('naukowobadawczej', 3), ('agaricus', 3), ('meslin', 3), ('cannabis', 3), ('sativa', 3), ('sce', 3), ('wodnobłotnych', 3), ('biorównoważności', 3), ('zacją', 3), ('zania', 3), ('przezeń', 3), ('betaagonistycznym', 3), ('hydrolizatory', 3), ('subpartycypację', 3), ('asistent', 3), ('medical', 3), ('hbv', 3), ('mycoplasma', 3), ('pneumoniae', 3), ('salmonelozy', 3), ('sanitarnoepidemiologiczne', 3), ('species', 3), ('tuberculosis', 3), ('niowych', 3), ('technicznoubezpieczeniowych', 3), ('ubezpiecze', 3), ('współkontrolę', 3), ('highly', 3), ('opcw', 3), ('hagera', 3), ('condensed', 3), ('div', 3), ('fangsong', 3), ('fb', 3), ('kaiti', 3), ('meiryo', 3), ...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_seq(words_with_lt3_occurrences,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrections\n",
    "Use Levenshtein distance and the frequency list, to determine the most probable correction of the words from the second list.\n",
    "> Decided that most probable corerections are 1 distance unit away from original misspelled word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lev_dist_1(word:str):\n",
    "    polish_letters = list('aąbcćdeęfghijklłmnńoóprsśtuwyzźż')\n",
    "    \n",
    "    wordlen= len(word)\n",
    "\n",
    "    without_letter = seq(range(0,wordlen)).map(lambda idx: word[:idx] + word[idx+1:])\n",
    "    \n",
    "    with_added_letter= seq(range(0,wordlen))\\\n",
    "        .flat_map(lambda idx: seq(polish_letters)\\\n",
    "            .map(lambda letter : (idx,letter))\n",
    "                 )\\\n",
    "        .map(lambda idx_letter: word[:idx_letter[0]]+ idx_letter[1] + word[idx_letter[0]:])\n",
    "    \n",
    "    with_replaced_letter = seq(range(0,wordlen))\\\n",
    "        .flat_map(lambda idx: seq(polish_letters)\\\n",
    "            .map(lambda letter : (idx,letter))\n",
    "                 )\\\n",
    "        .map(lambda idx_letter: word[:idx_letter[0]]+ idx_letter[1] + word[idx_letter[0]+1:]) \n",
    "    \n",
    "    return  pseq([without_letter,with_added_letter,with_replaced_letter])\\\n",
    "    .flat_map(lambda x: x)\n",
    "    \n",
    "def lev_dist_1_in_dict(word:str, polish:Set[str]):\n",
    "    return lev_dist_1(word).filter(lambda word : word in polish)\n",
    "    \n",
    "def lev_dist_2_in_dict(word:str, polish:Set[str]):\n",
    "    return lev_dist_1(word).flat_map(lambda word : lev_dist_1(word))\\\n",
    "    .distinct().filter(lambda word : word in polish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections = words_with_lt3_occurrences.filter(lambda x: len(x[0])>4)\\\n",
    ".map(lambda word: (word,lev_dist_1_in_dict(word[0],polish_dict)))#\\\n",
    "# .order_by(lambda x : - x[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('autologicznego', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nautologicznego', 'tautologicznego', 'antologicznego']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('przeszczepień', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['przeszczepie']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mikroprzedsiębiorcy', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('xxxvi', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apostille', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('adaptacyjnoopiekuńcze', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('naukowobadawcze', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('operacyjnoratowniczego', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('trifenyle', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('podwielokrotności', 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['powielokrotności']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def present(word_corrections:Tuple[str,Sequence]):\n",
    "    print(word_corrections[0])\n",
    "    display_seq(word_corrections[1],6)\n",
    "\n",
    "corrections.take(10).for_each(present)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
