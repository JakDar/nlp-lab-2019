{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:46:44.401958Z",
     "start_time": "2019-05-20T08:46:44.398089Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functional import seq\n",
    "from IPython.core.display import HTML\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-20T08:45:09.261251Z",
     "start_time": "2019-05-20T08:45:09.258254Z"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mblobs.bak/work/up_low50k/\u001b[00m\r\n",
      "├── \u001b[01;34mmodels\u001b[00m\r\n",
      "│   └── fwd_v50k_finetune_lm_enc.h5\r\n",
      "└── \u001b[01;34mtmp\u001b[00m\r\n",
      "    ├── sp-50k.model\r\n",
      "    └── sp-50k.vocab\r\n",
      "\r\n",
      "2 directories, 3 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree blobs.bak/work/up_low50k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai_model_path = \"./blobs.bak/work/up_low50k/models/fwd_v50k_finetune_lm_enc.h5\"\n",
    "sentencepiece_model_path = \"./blobs.bak/work/up_low50k/tmp/sp-50k.model\"\n",
    "sentencepiece_vocab_path = \"./blobs.bak/work/up_low50k/tmp/sp-50k.vocab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists_or_ex(path):\n",
    "    file = open(path,\"r\")\n",
    "    file.close()\n",
    "_ = [exists_or_ex(path) for path in [fastai_model_path, sentencepiece_model_path, sentencepiece_vocab_path]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "\n",
    "def highlighted(\n",
    "        highlight,\n",
    "        whole_text,\n",
    "):\n",
    "    return whole_text.replace(\n",
    "        highlight, colored(highlight, color=\"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "spm_processor = spm.SentencePieceProcessor()\n",
    "spm_processor.Load(sentencepiece_model_path)\n",
    "\n",
    "\n",
    "# spm_processor.LoadVocabulary(sentencepiece_vocab_path,threshold= 100)\n",
    "spm_processor.SetEncodeExtraOptions(\"bos:eos\")\n",
    "spm_processor.SetDecodeExtraOptions(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lm(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token, bidir=False,\n",
    "           tie_weights=True, qrnn=False):\n",
    "    rnn_enc = MultiBatchRNN(bptt, max_seq, n_tok, emb_sz, n_hid, n_layers, pad_token=pad_token, bidir=bidir, qrnn=qrnn)\n",
    "    enc = rnn_enc.encoder if tie_weights else None\n",
    "    return SequentialRNN(rnn_enc, LinearDecoder(n_tok, emb_sz, 0, tie_encoder=enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(50000, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(50000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (3): WeightDrop(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout()\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout()\n",
       "      (1): LockedDropout()\n",
       "      (2): LockedDropout()\n",
       "      (3): LockedDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=50000, bias=False)\n",
       "    (dropout): LockedDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "\n",
    "UNK_ID = 0\n",
    "PAD_ID = 1\n",
    "BOS_ID = 2\n",
    "EOS_ID = 3\n",
    "UP_ID  = 4\n",
    "bs=22\n",
    "\n",
    "em_sz,nh,nl = 400 ,1150,4\n",
    "\n",
    "bptt=5\n",
    "vs = len(spm_processor)\n",
    "\n",
    "lm = get_lm(bptt, 1000000, vs, em_sz, nh, nl, PAD_ID)\n",
    "lm = to_gpu(lm)\n",
    "load_model(lm[0],fastai_model_path)\n",
    "lm.reset()\n",
    "lm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMTextDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.x[idx]\n",
    "        return sentence[:-1], sentence[1:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_tokens(ids_, model, toks_at_once):  #toks_at_once wont be used\n",
    "    ids = [np.array(ids_)]\n",
    "    test_ds = LMTextDataset(ids)\n",
    "    test_samp = SortSampler(ids, key=lambda x: len(ids[x]))\n",
    "    dl = DataLoader(test_ds,\n",
    "                    bs,\n",
    "                    transpose=True,\n",
    "                    transpose_y=True,\n",
    "                    num_workers=1,\n",
    "                    pad_idx=PAD_ID,\n",
    "                    sampler=test_samp,\n",
    "                    pre_pad=False)\n",
    "\n",
    "    tensor1 = None\n",
    "    model.reset()  # todo:bcm - do or dont'?\n",
    "    with no_grad_context():\n",
    "        for (x, y) in dl:\n",
    "            tensor1 = model(x)\n",
    "    p = tensor1[0]\n",
    "    \n",
    "    #     arg = torch.sum(p[:-2],0)\n",
    "    arg =  p[-1]\n",
    "#     arg, _  = torch.max(p,dim=0)\n",
    "#     print(arg.size())\n",
    "    r = int(torch.argmax(arg))\n",
    "#     r = int(torch.multinomial(p[-1].exp(), 1))\n",
    "\n",
    "\n",
    "    while r in [ids_[-1]]: #, 24, BOS_ID,EOS_ID, UNK_ID]:\n",
    "        arg[r] = -1\n",
    "        r = int(torch.argmax(arg))\n",
    "\n",
    "    predicted_ids = [r]\n",
    "    return predicted_ids\n",
    "\n",
    "\n",
    "def next_word(ss, model, toks_at_once):\n",
    "    ids = spm_processor.encode_as_ids(ss)\n",
    "    return spm_processor.decode_ids(next_tokens(ids, model, toks_at_once))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_words_good(ss, lm, n_words, finishers=set([UNK_ID])):\n",
    "    initial_wip = spm_processor.encode_as_ids(ss)\n",
    "    wip = initial_wip\n",
    "    for i in range(n_words):\n",
    "        wip = wip + next_tokens(wip, lm, 1)\n",
    "\n",
    "    print(seq(wip).drop(len(initial_wip)))\n",
    "    return spm_processor.decode_ids(wip)\n",
    "#         seq(wip).take_while(lambda x: x not in finishers).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_words_bad(ss, lm, n_words, toks_at_once=1):\n",
    "    wip = ss\n",
    "    for i in range(n_words):\n",
    "        wip = wip + \" \" + next_word(wip, lm, toks_at_once)\n",
    "    return wip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Warszawa to największe\", \"Te zabawki należą do\",\n",
    "    \"Policjant przygląda się\", \"Na środku skrzyżowania widać\",\n",
    "    \"Właściciel samochodu widział złodzieja z\",\n",
    "    \"Prezydent z premierem rozmawiali wczoraj o\", \"Witaj drogi\",\n",
    "    \"Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie\",\n",
    "    \"Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie\",\n",
    "    \"Polscy naukowcy odkryli w Tatrach nowy gatunek istoty żywej. Zwięrzę to przypomina małpę, lecz porusza się na dwóch nogach i potrafi posługiwać się narzędziami. Przy dłuższej obserwacji okazało się, że potrafi również posługiwać się językiem polskim, a konkretnie gwarą podhalańską. Zwierzę to zostało nazwane\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32mWarszawa to największe\u001b[0m miasto w Polsce , które jest największym miastem w Polsce . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "\u001b[32mTe zabawki należą do\u001b[0m najbardziej popularnych i najbardziej popularnych w Polsce . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "\u001b[32mPolicjant przygląda się\u001b[0m , jak a ntyterrorystyczn y                                                                 \n",
      "\n",
      "\u001b[32mNa środku skrzyżowania widać\u001b[0m ślad y a w nim ślad y . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "\u001b[32mWłaściciel samochodu widział złodzieja z\u001b[0m                                                                      \n",
      "\n",
      "\u001b[32mPrezydent z premierem rozmawiali wczoraj o\u001b[0m tym , że w Polsce jest tak , że w Polsce jest ok . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "\u001b[32mWitaj drogi\u001b[0m , nie                                                                    \n",
      "\n",
      "\u001b[32mGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie\u001b[0m spodziewał , że to nie jest tak , że nie ma co się bać . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "\u001b[32mGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie\u001b[0m spodziewał a nie wiem jak to zrobić . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "\u001b[32mPolscy naukowcy odkryli w Tatrach nowy gatunek istoty żywej. Zwięrzę to przypomina małpę, lecz porusza się na dwóch nogach i potrafi posługiwać się narzędziami. Przy dłuższej obserwacji okazało się, że potrafi również posługiwać się językiem polskim, a konkretnie gwarą podhalańską. Zwierzę to zostało nazwane\u001b[0m na cześć                                                                    \n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(\"\")\n",
    "    lm.reset()\n",
    "    print(highlighted(sentence,next_words_bad(sentence, lm, 70)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Without rebuilding embedings from string for every word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1045, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mWarszawa to największe\u001b[0m miasto W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[558, 2, 24, 61, 174, 32625, 11, 17, 7, 42543, 0, 13, 4, 7, 39, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mTe zabawki należą do\u001b[0m najbardziej W Po związkuwiecie z się gnij ⁇ e ,  a ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[4, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mPolicjant przygląda się\u001b[0m , W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[2973, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mNa środku skrzyżowania widać\u001b[0m ślad W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mWłaściciel samochodu widział złodzieja z\u001b[0m  ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[49, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mPrezydent z premierem rozmawiali wczoraj o\u001b[0m tym W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[4, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mWitaj drogi\u001b[0m , W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n",
      "\n",
      "[22542, 2, 24, 61, 174, 32625, 11, 17, 7, 17111, 0, 230, 4, 9, 39, 29, 22, 27, 66, 78, 1498, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4]\n",
      "\u001b[32mGdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie\u001b[0m spodziewał W Po związkuwiecie z się gania ⁇ ją , i a to nie jest ma taklo  . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   ,\n",
      "\n",
      "[22542, 2, 24, 61, 174, 32625, 11, 17, 7, 17111, 0, 230, 4, 9, 39, 29, 22, 27, 66, 78, 1498, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4]\n",
      "\u001b[32mGdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie\u001b[0m spodziewał W Po związkuwiecie z się gania ⁇ ją , i a to nie jest ma taklo  . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   ,\n",
      "\n",
      "[12, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0, 7, 4, 0]\n",
      "\u001b[32mPolscy naukowcy odkryli w Tatrach nowy gatunek istoty żywej. Zwięrzę to przypomina małpę, lecz porusza się na dwóch nogach i potrafi posługiwać się narzędziami. Przy dłuższej obserwacji okazało się, że potrafi również posługiwać się językiem polskim, a konkretnie gwarą podhalańską. Zwierzę to zostało nazwane\u001b[0m na W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇   , ⁇ \n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    print(\"\")\n",
    "    lm.reset()\n",
    "    print(highlighted(sentence,next_words_good(sentence, lm, 70)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4838, 2, 24, 61, 49, 32625, 188, 4, 7, 6, 0, 10, 4, 17, 7, 22, 0, 7, 5, 0, 3, 7, 2, 0, 24, 7, 10, 0, 7, 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mama bardzo dobrze wydała swoje ulubione piosenki W Po tymwiecie czasie ,  w ⁇ y , się  nie ⁇   . ⁇   ⁇  W y ⁇   ,'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpucik = \"Mama bardzo dobrze wydała swoje ulubione\"\n",
    "next_words_good(inpucik,lm,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mama bardzo dobrze wydała swoje ulubione piosenki , które nie są w stanie wytrzymać . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_bad(\"Mama bardzo dobrze wydała swoje\",lm,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Policja nie może być w stanie w sposób skuteczny i skuteczny przeciwdziała ć wi a                                                          '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_bad(\"Policja nie może\",lm,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jest ciepły , ciepły , ciepły , ciepły , ciepły , ciepły , ciepły , ciepły . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_bad(\"Jest ciepły\",lm,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Był bardzo ciepły , ale nie miał ochoty na to , by go                                                            '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_bad(\"Był bardzo ciepły\",lm,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam rzucił piłkę burkowi, a ten nie dał rady . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_bad(\"Adam rzucił piłkę burkowi, a ten\",lm,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pan premier jest uprzejmy powiedzieć , że w tej chwili jest to niemożliwe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words_bad(\"Pan Premier jest\",lm,70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fork_venv",
   "language": "python",
   "name": "fork_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
